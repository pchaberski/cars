![](cover.png)  
![](blankpage.png) 

# Lightweight neural architectures by example - car model classification using GhostNet

**Abstract.** One of the branches of ongoing research in the field of computer vision and neural networks in general is to develop relatively simple architectures that have limited number of trainable parameters and FLOPS required to process data while still being able to achieve competitive accuracy in common tasks. This need for fast and memory-efficient designs is dictated mostly by the necessity of deploying such models on devices with limited computational power and memory, such as smartphones. This work attempts to explore the process of training and finetuning such networks from scratch, taking as an example one of the newest designs in the field (GhostNet developed by Huawei Noah's Ark Lab) and applying it to the Stanford Cars Dataset for car model recognition task.

**Keywords**: deep learning, neural networks, image recognition, mobile architectures, GhostNet, Stanford Cars Dataset

![](blankpage.png)  
